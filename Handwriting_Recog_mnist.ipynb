{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment1:\n",
    "\n",
    "Neural Network Implementation on Moon's Dataset\n",
    "Handwritting Recognition from MNIST Dataset(Numbers given 3&5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\riti chakraborty\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "c:\\users\\riti chakraborty\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Calling the Required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from mnist import MNIST\n",
    "import matplotlib.cm as cm\n",
    "from numpy.random import randn\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing, utils\n",
    "\n",
    "#For reading MNIST Dataset\n",
    "import gzip\n",
    "import sklearn.learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#For creating Confution Matrix\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Moons Data - Reading from CSV \n",
    "# Using Pandas read CSV to import the dataset\n",
    "moon = pd.read_csv('moons400.csv')\n",
    "\n",
    "# With the help of Utils libraries, the data is shuffled which is later on divided in training and testing data.\n",
    "moon = utils.shuffle(moon)\n",
    "\n",
    "#Seperating out Attributes and classes\n",
    "X=moon[['X0', 'X1']].as_matrix()\n",
    "y=moon[['Class']].as_matrix()\n",
    "\n",
    "#Dividing the data into training and Testing\n",
    "Test_Moon = X[0:100,]\n",
    "Train_Moon = X[101:400,]\n",
    "label_test = y[0:100,]\n",
    "label_train = y[101:400,]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:/Users/Riti Chakraborty/AppData/Local/Programs/Python/Python36-32/Scripts/GZ_IP/train-images-idx3-ubyte.gz\n",
      "Extracting C:/Users/Riti Chakraborty/AppData/Local/Programs/Python/Python36-32/Scripts/GZ_IP/train-labels-idx1-ubyte.gz\n",
      "Extracting C:/Users/Riti Chakraborty/AppData/Local/Programs/Python/Python36-32/Scripts/GZ_IP/t10k-images-idx3-ubyte.gz\n",
      "Extracting C:/Users/Riti Chakraborty/AppData/Local/Programs/Python/Python36-32/Scripts/GZ_IP/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#MNIST Dataset\n",
    "\n",
    "\n",
    "###################The code snippet for reading the gzip files(MNIST Data) has been taken from github.##############################\n",
    "WORK_DIRECTORY = 'data'\n",
    "IMAGE_SIZE = 28\n",
    "NUM_CHANNELS = 1\n",
    "PIXEL_DEPTH = 255\n",
    "NUM_LABELS = 10\n",
    "def extract_data(filename, num_images):\n",
    " \n",
    "  print('Extracting', filename)\n",
    "  with gzip.open(filename) as bytestream:\n",
    "    bytestream.read(16)\n",
    "    buf = bytestream.read(28 * 28 * num_images)\n",
    "    data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "    data = data.reshape(num_images, 28, 28, 1)\n",
    "    return data\n",
    "\n",
    "\n",
    "def extract_labels(filename, num_images):\n",
    "  \"\"\"Extract the labels into a vector of int64 label IDs.\"\"\"\n",
    "  print('Extracting', filename)\n",
    "  with gzip.open(filename) as bytestream:\n",
    "    bytestream.read(8)\n",
    "    buf = bytestream.read(1 * num_images)\n",
    "    labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "  return labels\n",
    "\n",
    "train_data = extract_data(\"C:/Users/Riti Chakraborty/AppData/Local/Programs/Python/Python36-32/Scripts/GZ_IP/train-images-idx3-ubyte.gz\", 60000)\n",
    "train_labels = extract_labels(\"C:/Users/Riti Chakraborty/AppData/Local/Programs/Python/Python36-32/Scripts/GZ_IP/train-labels-idx1-ubyte.gz\", 60000)\n",
    "test_data = extract_data(\"C:/Users/Riti Chakraborty/AppData/Local/Programs/Python/Python36-32/Scripts/GZ_IP/t10k-images-idx3-ubyte.gz\", 10000)\n",
    "test_labels = extract_labels(\"C:/Users/Riti Chakraborty/AppData/Local/Programs/Python/Python36-32/Scripts/GZ_IP/t10k-labels-idx1-ubyte.gz\", 10000)\n",
    "#######################The code snippet for reading the gzip files has been taken from github.##############################\n",
    "\n",
    "\n",
    "#Reshaping the Imported data as per requirement.\n",
    "X_train11 = pd.DataFrame(np.array(train_data).reshape(60000,784))\n",
    "y_train11 = pd.DataFrame(np.array(train_labels).reshape(60000,1))\n",
    "\n",
    "X_test1 = pd.DataFrame(np.array(test_data).reshape(10000,784))\n",
    "y_test1 = pd.DataFrame(np.array(test_labels).reshape(10000,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Cleaning: Extracting the data have 3 & 5 as labels\n",
    "#Training Data\n",
    "X_train11['label'] = y_train11[0]\n",
    "type(X_train11)\n",
    "Tf=X_train11.loc[X_train11['label']==3]\n",
    "Tf2=X_train11.loc[X_train11['label']==5]\n",
    "Training_Final=Tf.append(Tf2)\n",
    "\n",
    "#Assigning 3 to 1 and 5 to 0\n",
    "#For binary classification\n",
    "Training_Final['label'] = Training_Final['label'].map({3: 1, 5: 0})\n",
    "Training_Final\n",
    "Training_Final.shape\n",
    "X__train=Training_Final.drop('label', axis=1).as_matrix()\n",
    "y__train=Training_Final[['label']].as_matrix()\n",
    "\n",
    "#Data Cleaning: Extracting the data have 3 & 5 as labels\n",
    "#Testing Data\n",
    "X_test1['label'] = y_test1[0]\n",
    "type(X_test1)\n",
    "Tf_3=X_test1.loc[X_test1['label']==3]\n",
    "Tf_5=X_test1.loc[X_test1['label']==5]\n",
    "Test_final=Tf_3.append(Tf_5)\n",
    "\n",
    "\n",
    "#Assigning 3 to 1 and 5 to 0\n",
    "#For binary classification\n",
    "Test_final['label'] = Test_final['label'].map({3: 1, 5: 0})\n",
    "#Test_final\n",
    "#Test_final.shape\n",
    "X__test=Test_final.drop('label', axis=1).as_matrix()\n",
    "y__test=Test_final[['label']].as_matrix()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm:\n",
    "\n",
    "1. Our Neural Network has three layers i.e. one input layer with no. of nodes equal to the number of attributes. \n",
    "2. For moon's dataset no of attrs = 2 (X0 & X1) therefore input node=2. \n",
    "3. For MNIST Dataset no of attr = 784 there input nodes = 784\n",
    "4. The second layer is the hidden layer. It has 5 hidden nodes.\n",
    "5. The Output layer. It has one node for binary classification.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid Function : Activation Function\n",
    "In Artificial Neural network , Linear combination of input is calculated and applied to activation function. The basic function of Sigmoid is to add the non linearity. In absense of such activation function, the neural network will only work for linear models and not for non linear models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the Sigmoid Function\n",
    "def sigmoid(x, derive=False):\n",
    "    if derive==True:\n",
    "        return x * (1 - x)\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Calculating the total length of seperate datsets (Moon's Data)\n",
    "moon_total_train_labelsize = len(label_train)\n",
    "moon_total_test_labelsize = len(label_test)\n",
    "\n",
    "#Calculating the total length of seperate datsets (Mnist Data)\n",
    "mnist_total_train_labelsize = len(y__train)\n",
    "mnist_total_test_labelsize = len(y__test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed Forward ( Forward Propagation )\n",
    "Feed forward neural netwroks are the ones in which the input only flows in one forward direction. There is no feedback and thus called as Forward propagation. In the code below, the neural network is having 3 layers: Input, one hidden and one output layer.\n",
    "\n",
    "Initially the random weights are assigned and by adding the bias to the product of weight and input, the output fromt the first layer is obtained. The output is then passed to the sigmoid activation function. The similar steps are carried out in the hidden layer and the output z22 is obtained.\n",
    "\n",
    "The Calculation are carried out as follows: Below are the notations used:\n",
    "\n",
    "h: output a: Activation functions w: Weights x: input b: Bias\n",
    "\n",
    "First the activation functions are calculated as: a12( Activation of first node in 2nd layer, i.e, hidden layer )= function(W11x1+ w12x2 + b1) a22= function(W21x1+w22x2+b2)\n",
    "\n",
    "The output is :\n",
    "\n",
    "h= weightsactivationfunction + bias*\n",
    "\n",
    "\n",
    "Back Propagation\n",
    "Back propogation is usually carried out in feed forward neural network for training purpose. The output from the feed forward neural network is checked against the actual required output to find the error. Then with the help of back propogation, the wieghts are adjusted so as to reduce the loss and increase the accuracy in training the model.\n",
    "The backpropagation algorithm works as follows:\n",
    "\n",
    "1. Initialize the weights to random numbers. Repeat until convergence or max iterations. repeat for each training example(1 epoch)\n",
    "\n",
    "2. The new weights are calculated by subtracting the product of error and output of next layer and learning rate.\n",
    "\n",
    "3. New Weight= Original Weight - learning ate ( output * error term )\n",
    "\n",
    "\n",
    "\n",
    "Learning Rate\n",
    "The value of cost function is minimized with the help of gradient descent function.The function is used to get the minimum value of the cost function and reach the convergence by taking the steps “downhill” controlled by alpha called as learning rate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAINING NEURAL NETWORK\n",
    "#Setting output node to 1\n",
    "outputnodes = 1 \n",
    "\n",
    "\n",
    "#defining a function to program the network\n",
    "def network(inputnodes, hiddennodes, epoch, x, y, ls, learningrate):\n",
    "   \n",
    "    #Initialising random seed\n",
    "    np.random.seed(60)\n",
    "    \n",
    "    #Assigning Weights randomly to the nodes in layers\n",
    "    W1 = np.random.randn(inputnodes, hiddennodes) \n",
    "    W1 = W1/np.amax(W1)\n",
    "    b1 = np.ones((1, hiddennodes))\n",
    "    W2 = np.random.randn(hiddennodes, 1)\n",
    "    W2 = W2/np.amax(W2)\n",
    "    b2 = np.ones((1, 1))\n",
    "\n",
    "\n",
    "    #Creating a tuple to store the final weights and biases\n",
    "    finalWeightsandbiases = {}\n",
    "    \n",
    "    #Implementing Gradient Descent: Passing the entire dataset in each iteration.\n",
    "    for i in range(epoch):\n",
    "\n",
    "        #Forward Propagation Algorithm\n",
    "        #Layer1\n",
    "        z11= sigmoid(np.dot(x, W1) + b1)\n",
    "        \n",
    "        #Layer2\n",
    "        z22= sigmoid(np.dot(z11, W2) + b2)#layer2\n",
    "    \n",
    "        #Calculating error in prediction\n",
    "        Train_error = y - np.round(np.absolute(z22))\n",
    "          \n",
    "        #Calculation total number of correct predictions\n",
    "        correctpred = [num for num in Train_error if np.any(num) == 0 ]\n",
    "        \n",
    "        #Implementing Back Propagation\n",
    "        #Output to hidden\n",
    "        delta2 = (z22 - y) * sigmoid(z22)\n",
    "        W2 = W2 - learningrate * (z11.T.dot(delta2))\n",
    "        b2 = b2 - learningrate * np.sum(delta2)\n",
    "        ############\n",
    "        \n",
    "        #hidden to Input layer\n",
    "        delta1 = (delta2.dot(W2.T)) * sigmoid(z11)\n",
    "        W1 = W1 - learningrate * (x.T.dot(delta1))\n",
    "        b1 = b1 - learningrate * np.sum(delta1)\n",
    "        ############\n",
    "        \n",
    "        #Updating th Tuple\n",
    "        finalWeightsandbiases = (W1,b1,W2,b2)\n",
    "    \n",
    "    #Printing Accuracy  \n",
    "    Train_Accuracy = (len(correctpred)/ls)*100\n",
    "    print(\"Training Set Accuracy:\", Train_Accuracy)    \n",
    "    \n",
    "    #returning the Weights and Biases.\n",
    "    return finalWeightsandbiases\n",
    "    \n",
    "   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_Testdata(finalWeightsandbiases, x, y, ls):\n",
    "    \n",
    "    #Pred are the lists created\n",
    "    #Pred is for storing the predicted labels\n",
    "    pred=[]\n",
    "    \n",
    "    #Initialising weights and biases to a tuple\n",
    "    W1, b1, W2, b2 = finalWeightsandbiases\n",
    "    \n",
    "    # Forward propagation\n",
    "    z11 = np.dot(x,W1) + b1\n",
    "    a1 = sigmoid(z11)\n",
    "    z22 = sigmoid(np.dot(a1,W2) + b2)\n",
    "    \n",
    "    # Calculating the errors by subtracting the predicted result from the actual one. *np.round & np.absolute* functions are used\n",
    "    # to get the absolute rounded value of the output.\n",
    "    Test_error = y - np.round(np.absolute(z22))\n",
    "    \n",
    "    #appending the predicted results to pred[]\n",
    "    pred.append(np.round(np.absolute(z22)))\n",
    "  \n",
    "    # Correctly predicted results are checked below by checking the result of the Test error. If the result is correctly predicted\n",
    "    # the output of the test error would be 0 and hence later on the length of the correctTest pred is used to calculate the accuracy.\n",
    "    correctTestpred = [n for n in Test_error if np.any(n) == 0 ]\n",
    "    \n",
    "    # Accuracy of the trained model is calculated below.\n",
    "    # It is calculated by checking the number of correctly predicted results over the total number of results.\n",
    "    Test_Accuracy = (len(correctTestpred)/ls)*100\n",
    "    print(\"Testing Set Accuracy:\", Test_Accuracy)\n",
    "    \n",
    "    \n",
    "    #plot confusion matrix\n",
    "    # Confusion matrix is the visualization of the performance of the model. It is the matrix plot having the counts of actual results \n",
    "    # and predicted results.\n",
    "    # The confusion matrix is obtained using the matplotlib and seaborn library.\n",
    "    ax=plt.axes()\n",
    "    arr = metrics.confusion_matrix(y, np.round(z22), sample_weight=None)\n",
    "    con_df = pd.DataFrame(arr, columns = [\"Predicted_0\", \"Predicted_1\"],index=[\"Actual_0\", \"Actual_1\"])\n",
    "    sb.heatmap(con_df, annot=True,annot_kws={\"size\": 8}, fmt='g', cmap='Blues', ax=ax)\n",
    "    ax.set_title('Confusion Matrix - Test Phase')\n",
    "    plt.show()\n",
    "     \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting number of epochs to 40. This is means thats the entire dataset will be train 40 times. Processing the whole data is also \n",
    "#also known as gradient descent.\n",
    "epoch=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moon's Data \n",
      "Training Set Accuracy: 75.91973244147158\n",
      "Testing Set Accuracy: 81.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc6f5e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Training and testing Moon's Data\n",
    "########################################### BY: SHREYA NAGARKAR #####################################################\n",
    "print(\"Moon's Data \")\n",
    "outputMoon = network(2, 5, epoch,Train_Moon,label_train, moon_total_train_labelsize, learningrate=0.001)\n",
    "TestModel = predict_Testdata(outputMoon,Test_Moon,label_test,moon_total_test_labelsize)\n",
    "#print(TestModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation on Moon's Dataset\n",
    "### by: Shreya\n",
    "1. Accuracy obtained is 79% on Training Data and 71% on Testing Data. We can say the algorithm performed fairly well but it did fail to predict some labels. \n",
    "\n",
    "2. From the confusion matrix it is observed that 29 input entries were wrongly predicted out of 100 input entries from the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mnist's Data \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\riti chakraborty\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in exp\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy: 91.94944598337949\n",
      "Testing Set Accuracy: 93.37539432176656\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc6f5a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Training and testing MNIST Data\n",
    "print(\"Mnist's Data \")\n",
    "outputdigits = network(784, 3, epoch, X__train, y__train, mnist_total_train_labelsize, learningrate=0.0001)\n",
    "TestModel = predict_Testdata(outputdigits,X__test,y__test, mnist_total_test_labelsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation on MNIST Dataset\n",
    "We are classifying between 3 and 5\n",
    "1. From the confusion matrix it is observed that, out of 1902 records 1776 records were correctly classified.\n",
    "2. Therefore the accuracy is good for both Training Set as well as testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhancement 1\n",
    "\n",
    "The function of the model above is optimized by Minibatch Gradient Descent Algorithm. In minibatch gradient descent algorithm, instead of sending the complete data, it is sent in batches and the model is built and tested. The batch size taken is 1150 and the total data is 11552. Hence, The minibatch gradient loop is worked for 10 times. Initially the data of 1150 rows is taken as a first minibatch and later on from 1151 to 2230 and so on. The test and train data is taken in this manner in minibatches and model is trained and tested for 40 epochs. The advantage of using minibatch gradient descent algorithm is , since the data is taken in batches, the convergence is calculated for each batch and also the computation time of the model decreases.\n",
    "\n",
    "Reference : https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the number of epochs\n",
    "epoch = 40\n",
    "# Defining the function prediction where the input parameter passed as features, labels, learning rate and the model trained. \n",
    "def predict_enhanced(model, x, y, ls):\n",
    "    \n",
    "# Pred and Test_error are the lists created\n",
    "    pred=[]\n",
    "    W1, b1, W2, b2 = model\n",
    "    Test_error=[]\n",
    "    \n",
    "#Forward propagation\n",
    "\n",
    "    z11 = np.dot(x,W1) + b1\n",
    "    a1 = sigmoid(z11)\n",
    "    z22 = sigmoid(np.dot(a1,W2) + b2)\n",
    "    \n",
    "# Calculating the errors by subtracting the predicted result from the actual one. *np.round & np.absolute* functions are used\n",
    "# to get the absolute rounded value of the output.\n",
    "\n",
    "    Test_error = y- np.round(np.absolute(z22))\n",
    "    \n",
    "# Correctly predicted results are checked below by checking the result of the Test error. If the result is correctly predicted\n",
    "# the output of the test error would be 0 and hence later on the length of the correctTest pred is used to calculate the accuracy.\n",
    "    correctTestpred = [n for n in Test_error if np.any(n) == 0 ]\n",
    "    \n",
    "# Accuracy of the trained model is calculated below.\n",
    "# It is calculated by checking the number of correctly predicted results over the total number of results.\n",
    "    accuracy=(len(correctTestpred)/ls)*100 \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def build_model_enhanced(inputnodes,hiddennodes,epoch, x, y, ls, learningrate):\n",
    "    \n",
    "    np.random.seed(9)    \n",
    "    # Initializing weights and biases.\n",
    "    W1 = np.random.randn(inputnodes, hiddennodes)\n",
    "    W1 = W1/np.amax(W1)\n",
    "    b1 = np.ones((1, hiddennodes))\n",
    "    W2 = np.random.randn(hiddennodes, 1)\n",
    "    W2 = W2/np.amax(W2)\n",
    "    b2 = np.ones((1, 1))\n",
    "\n",
    "\n",
    "    model = {}\n",
    "    accuracy = []\n",
    "    for i in range(epoch):\n",
    "\n",
    "        # Forward propagation\n",
    "        #Calculating the output from the first layer\n",
    "        z11= sigmoid(np.dot(x, W1) + b1)\n",
    "        # Calculating the output from the second layer\n",
    "        z22= sigmoid(np.dot(z11, W2) + b2)#layer2\n",
    "        #Error is calculated by decreasing the predicted value of the output from the actual one.\n",
    "        Train_error = y - np.round(np.absolute(z22))\n",
    "        # Calculating the accuracy.\n",
    "        #If both, actual and predicted value matches, the difference would be 0 and this is used to calculate the accuracy.\n",
    "        correctpred = [num for num in Train_error if np.any(num) == 0 ]\n",
    "     \n",
    "        # Backpropagation\n",
    "        #Output to hidden\n",
    "        delta2 = (z22 - y) * sigmoid(z22)\n",
    "        # Updating weights and biases\n",
    "        W2 = W2 - learningrate * (z11.T.dot(delta2))\n",
    "        b2 = b2 - learningrate * np.sum(delta2)\n",
    "        ############\n",
    "        #hidden to Input layer\n",
    "        delta1 = (delta2.dot(W2.T)) * sigmoid(z11)\n",
    "        W1 = W1 - learningrate * (x.T.dot(delta1))\n",
    "        b1 = b1 - learningrate * np.sum(delta1)\n",
    "        ############\n",
    "        # The updated weights and biases are returned which are used to predict. model{} consists of updated weights and biases.\n",
    "        model = (W1,b1,W2,b2)\n",
    "         \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "The above model is trained and tested for the given Mnists' dataset. The accuracy in testing is observed to be (~82 %)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\riti chakraborty\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in exp\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model after applying minibatch gradient descent is:   81.80862250262881\n"
     ]
    }
   ],
   "source": [
    "# Setting the number of iterations and size of a minibatch\n",
    "Mtesting=[]\n",
    "\n",
    "for minibatch_size in [500, 1000, 1500, 2000, 3000, 4000, 7000, 8000, 10000, 11552]:\n",
    "    i = 0\n",
    "    X__train_mini = X__train[i:i + minibatch_size]\n",
    "    y__train_mini = y__train[i:i + minibatch_size]\n",
    "    Mtr = build_model_enhanced(784,5,40,X__train_mini, y__train_mini,mnist_total_test_labelsize,learningrate=0.0001)            \n",
    "    #i=minibatch_size\n",
    "Mts=predict_enhanced(Mtr, X__test, y__test, mnist_total_test_labelsize)\n",
    "Mtesting.append(Mts)    \n",
    "            \n",
    "#Printing the final accuracy for the testing data\n",
    "print(\"Accuracy of the model after applying minibatch gradient descent is:  \", np.mean(Mtesting))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhancement 2\n",
    "1. Regularization is basically used to prevent overfitting. \n",
    "2. Model overfitting happens when the neural network is trained excessively.\n",
    "3. This causes neural network perform very well on training data but poorly on testing data. \n",
    "4. Regularization helps in reducing the variance of the weight so as to decrease the error.\n",
    "5. In the algorithm below the regularization_coefm is added to the Weights generated in order to handle the spread of the values after assigning random weights before building the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "   ### TRAINING NEURAL NETWORK\n",
    "#Setting output node to 1\n",
    "outputnodes = 1 \n",
    "regularization_coeff = 0.01\n",
    "#defining a function to program the network\n",
    "def networkRiti(inputnodes, hiddennodes, epoch, x, y, ls, learningrate):\n",
    "   \n",
    "    #Initialising random seed\n",
    "    np.random.seed(60)\n",
    "    \n",
    "    #Assigning Weights randomly to the nodes in layers\n",
    "    W1 = np.random.randn(inputnodes, hiddennodes) \n",
    "    W1 = W1/np.amax(W1)\n",
    "    b1 = np.ones((1, hiddennodes))\n",
    "    W2 = np.random.randn(hiddennodes, 1)\n",
    "    W2 = W2/np.amax(W2)\n",
    "    b2 = np.ones((1, 1))\n",
    "\n",
    "\n",
    "    #Creating a tuple to store the final weights and biases\n",
    "    finalWeightsandbiases = {}\n",
    "    \n",
    "    #Implementing Gradient Descent: Passing the entire dataset in each iteration.\n",
    "    for i in range(epoch):\n",
    "\n",
    "        #Forward Propagation Algorithm\n",
    "        #Layer1\n",
    "        z11= sigmoid(np.dot(x, W1) + b1)\n",
    "        \n",
    "        #Layer2\n",
    "        z22= sigmoid(np.dot(z11, W2) + b2)#layer2\n",
    "    \n",
    "        #Calculating error in prediction\n",
    "        Train_error = y - np.round(np.absolute(z22))\n",
    "          \n",
    "        #Calculation total number of correct predictions\n",
    "        correctpred = [num for num in Train_error if np.any(num) == 0 ]\n",
    "       \n",
    "        #Back Propagation\n",
    "        #Output to hidden\n",
    "        #Applying Regularization term - enhancement\n",
    "        delta2 = (z22 - y) * sigmoid(z22)\n",
    "        W2 = W2 + regularization_coeff * W2\n",
    "        W2 = W2 - learningrate * (z11.T.dot(delta2))\n",
    "        b2 = b2 - learningrate * np.sum(delta2)\n",
    "        \n",
    "        #hidden to Input layer\n",
    "        delta1 = (delta2.dot(W2.T)) * sigmoid(z11)\n",
    "        W1 = W1 + regularization_coeff * W1\n",
    "        W1 = W1 - learningrate * (x.T.dot(delta1))\n",
    "        b1 = b1 - learningrate * np.sum(delta1)\n",
    "        ############\n",
    "        \n",
    "        #Updating the final weights and biases\n",
    "        finalWeightsandbiases = (W1,b1,W2,b2)\n",
    "        \n",
    "        \n",
    "    Train_Accuracy = (len(correctpred)/ls)*100\n",
    "\n",
    "    print(\"Training Set Accuracy:\", Train_Accuracy)    \n",
    "    #plt.plot(accuracy)\n",
    "    #plt.ylabel('Accuracy')\n",
    "    #plt.show()\n",
    "    return finalWeightsandbiases\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mnist's Data \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\riti chakraborty\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in exp\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy: 92.41689750692521\n",
      "Testing Set Accuracy: 93.84858044164038\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc6f5750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Training and testing the data \n",
    "print(\"Mnist's Data \")\n",
    "outputdigits = networkRiti(784, 3, epoch, X__train, y__train, mnist_total_train_labelsize, learningrate=0.0001)\n",
    "TestModel = predict_Testdata(outputdigits,X__test,y__test, mnist_total_test_labelsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation - on MNIST Dataset\n",
    "\n",
    "After applying regularization to the weights:-\n",
    "1. There is a slight increase in both testing and training accuracy.\n",
    "2. The number of correctly predicted records from the test dataset is more.\n",
    "3. This shows that the performance of the model has improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links used for the above enhancement:\n",
    "    \n",
    "1: https://stats.stackexchange.com/questions/141555/how-does-regularization-reduce-overfitting\n",
    "\n",
    "2: https://visualstudiomagazine.com/articles/2017/09/01/neural-network-l2.aspx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
